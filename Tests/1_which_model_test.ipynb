{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389e6b78-bbfa-4a13-918c-45b60086c945",
   "metadata": {},
   "source": [
    "First test to see which LLM to use\n",
    "\n",
    "Options:\n",
    "- gpt3-turbo\n",
    "- LLama\n",
    "- gpt4.1-nano\n",
    "- gpt4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff61f676-c8da-4227-aec6-02b8f7e039f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.78.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Downloading openai-1.78.0-py3-none-any.whl (680 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.4/680.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "Successfully installed jiter-0.9.0 openai-1.78.0\n",
      "Collecting PyMuPDF\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.25.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install --upgrade PyMuPDF\n",
    "from API_KEY import API_KEY\n",
    "from LLAMA_KEY import LLAMA_KEY\n",
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "output_folder = \"limitations_2024\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "inline_limitations = re.compile(\n",
    "    r\"\\b(Limitations?|Challenges?)[:\\s]+(.{100,1500}?)\",\n",
    "    flags=re.IGNORECASE | re.DOTALL\n",
    ")\n",
    "\n",
    "find_limitations = re.compile(\n",
    "    r\"(?:^|\\n)(?:\\d{0,2}[\\.]\\s*)?\"\n",
    "    r\"(limitations|limitation|conclusions and limitations|future work|conclusion (?:and|&) future work|limitations (?:and|&) future work|conclusion|conclusions|discussion|conclusion (?:and|&) discussion|conclusions|research limitations|study limitations|challenges)\"\n",
    "    r\"(?::)?\\s*\\n+(.*?)(?=\\n\\s*(?:\\d{1,2}[\\.]+\\s*)?[A-Z][A-Za-z0-9, \\-]{3,60}\\n|\\Z)\",\n",
    "    flags=re.IGNORECASE | re.DOTALL\n",
    ")\n",
    "\n",
    "keywords = [\"limitations\", \"conclusions and limitations\",\"future work\", \"challenges\", \"limitation\", \"study limitations\", \"research limitations\", \"limitations and future work\", \"conclusion and future work\", \"conclusion & future work\"]\n",
    "def find_section(txt):\n",
    "    paper_sections = {}\n",
    "    for f in find_limitations.finditer(txt):\n",
    "        title = f.group(1).strip().lower()\n",
    "        text = f.group(2).strip()\n",
    "        if not text.lower().startswith(\"question: does the paper discuss the limitations\"):\n",
    "            paper_sections[title] = text\n",
    "    has_limitations = any(k in paper_sections for k in keywords)\n",
    "    if not has_limitations:\n",
    "        for section_title in [\"conclusion\", \"conclusions and limitations\" \"conclusions\", \"discussion\", \"conclusion and discussion\", \"conclusion & discussion\"]:\n",
    "            section_text = paper_sections.get(section_title)\n",
    "            if section_text:\n",
    "                match = inline_limitations.search(section_text)\n",
    "                if match:\n",
    "                    paper_sections[\"inline\"] = match.group(1).strip()\n",
    "                break\n",
    "    return paper_sections\n",
    "    \n",
    "def extract_limitations(path):\n",
    "    doc = fitz.open(path)\n",
    "    txt = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        txt += page.get_text(\"text\") + \"\\n\"\n",
    "    title_paper = os.path.basename(path)\n",
    "    paper_sections = find_section(txt)\n",
    "    return title_paper, paper_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f500e445-c7d9-49d1-864e-620d895e7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = API_KEY)\n",
    "def bullet_list(text, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\":f\"You are a research assistant that summarizes academic limitation sections.\"},\n",
    "            {\"role\": \"user\", \"content\":f\"Convert the following text into 3-6 clear bullet points:\\n {text}\"}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return (response.choices[0].message.content).strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2403e295-40bc-498e-af4d-1e57cb704197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.4.0+cu121)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.5.82)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, safetensors, regex, hf-xet, huggingface-hub, tokenizers, transformers, accelerate\n",
      "Successfully installed accelerate-1.6.0 hf-xet-1.1.0 huggingface-hub-0.31.1 regex-2024.11.6 safetensors-0.5.3 sentencepiece-0.2.0 tokenizers-0.21.1 transformers-4.51.3\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (2.4.0+cu121)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.11/site-packages (from torch<3,>=2.0->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=2.0->bitsandbytes) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f1a93a0cb54eeabb1b01936bfdb639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214f05903a034874989734f1e3c6aa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e79d9169aba4277bb8c6d6950234d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d473f563b3412d9c693ac840be1c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66669cf3889d430cbd39cd469f4f2e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c1b04d59a8460881487b69f4e991c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d211569955d84bcfb7bc367cd51bc9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcdfdbb1264481f8046c735a31ffe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82484fb4672481581401a832091d9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b3b59901c945f5ad9eb36c55027b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate sentencepiece\n",
    "!pip install bitsandbytes\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=LLAMA_KEY)\n",
    "llama_pipeline = pipeline(\"text-generation\", model = \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "                   torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "def bullet_list_llama(text):\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "    You are a research assistant that summarizes academic limitation sections into 3-6 clear bullet points.\n",
    "    ### Input: {text}\n",
    "    ### Output: -\"\"\"\n",
    "\n",
    "    \n",
    "    output = llama_pipeline(prompt, max_new_tokens=300, do_sample=True, top_p=0.95, temperature = 0.7)\n",
    "    generated = output[0][\"generated_text\"]\n",
    "    if '### Output:' in generated:\n",
    "        return generated.split(\"### Output:\")[-1].strip()\n",
    "    elif \"- \" in generated:\n",
    "        return generated[generated.find(\"- \"):].strip()\n",
    "    else:\n",
    "        return generated.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b1e506-0c74-4288-9b2b-d3c746b436e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "year = 2024\n",
    "full_papers_folder = f\"Papers\"\n",
    "\n",
    "papers = [paper for paper in os.listdir(full_papers_folder) if paper.endswith(\".pdf\")]\n",
    "limitations_gpt3 = []\n",
    "limitations_gpt4_nano = []\n",
    "limitations_gpt4 = []\n",
    "limitations_llama = []\n",
    "\n",
    "for paper in papers:\n",
    "    path = os.path.join(full_papers_folder, paper)\n",
    "    name, sections = extract_limitations(path)\n",
    "    for l in keywords:\n",
    "        section_text = sections.get(l)\n",
    "        if section_text and section_text.strip().lower() != \"question: does the paper discuss the limitations\" and (\"conclusions and limitations\" in sections or \"conclusions\" in sections or \"conclusion\" in sections or \"discussion\" in sections or \"conclusion and discussion\" in sections or \"conclusion & discussion\" in sections):\n",
    "            # Generate bullet points\n",
    "            bullets_gpt3_turbo = bullet_list(section_text, \"gpt-3.5-turbo\")\n",
    "            bullets_gpt4_nano = bullet_list(section_text, \"gpt-4.1-nano\")\n",
    "            bullets_gpt4 = bullet_list(section_text, \"gpt-4.1\")\n",
    "            bullets_llama = bullet_list_llama(section_text)\n",
    "            \n",
    "            \n",
    "            limitations_gpt3.append({\"paper\": name, \"target\": section_text, \"target_bullets\": bullets_gpt3_turbo})\n",
    "            limitations_gpt4_nano.append({\"paper\": name, \"target\": section_text, \"target_bullets\": bullets_gpt4_nano})\n",
    "            limitations_gpt4.append({\"paper\": name, \"target\": section_text, \"target_bullets\": bullets_gpt4})\n",
    "            limitations_llama.append({\"paper\": name, \"target\": section_text, \"target_bullets\": bullets_llama})\n",
    "            break\n",
    "output_file1 = os.path.join(output_folder, f\"limitations_only_gpt3_turbo.json\")\n",
    "with open(output_file1, 'w') as out_file:\n",
    "    json.dump(limitations_gpt3, out_file, indent=4)\n",
    "output_file2 = os.path.join(output_folder, f\"limitations_only_gpt4_nano.json\")\n",
    "with open(output_file2, 'w') as out_file:\n",
    "    json.dump(limitations_gpt4_nano, out_file, indent=4)\n",
    "output_file3 = os.path.join(output_folder, f\"limitations_only_gpt4.json\")\n",
    "with open(output_file3, 'w') as out_file:\n",
    "    json.dump(limitations_gpt4, out_file, indent=4)\n",
    "output_file4 = os.path.join(output_folder, f\"limitations_only_llama.json\")\n",
    "with open(output_file4, 'w') as out_file:\n",
    "    json.dump(limitations_llama, out_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd3920-41a2-405f-a0d7-612aba07e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas sentence-transformers\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model_output_folder = \"limitations_2024\"\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "model_files = {\n",
    "    \"gpt3.5-turbo\": \"limitations_only_gpt3_turbo.json\",\n",
    "    \"gpt4.1-nano\": \"limitations_only_gpt4_nano.json\",\n",
    "    \"gpt4.1\": \"limitations_only_gpt4.json\",\n",
    "    \"meta-llama\": \"limitations_only_llama.json\",\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_bullets(bullets):\n",
    "    lines = [l.strip() for l in bullets.split(\"\\n\") if l.strip() and l.startswith(\"-\")]\n",
    "    bullet_count = len(lines)\n",
    "    has_duplicates = len(set(lines)) < bullet_count\n",
    "    avg_length = sum(len(l) for l in lines) / bullet_count if bullet_count > 0 else 0\n",
    "\n",
    "    # Embedding diversity\n",
    "    if bullet_count > 1:\n",
    "        embeddings = model.encode(lines, convert_to_tensor=True)\n",
    "        sim_matrix = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "        avg_sim = sim_matrix.mean().item()\n",
    "        diversity = round(1 - avg_sim, 4) \n",
    "    else:\n",
    "        diversity = 0.0\n",
    "\n",
    "    return {\n",
    "        \"bullet_count\": bullet_count,\n",
    "        \"has_duplicates\": has_duplicates,\n",
    "        \"format_ok\": all(l.startswith(\"-\") for l in lines),\n",
    "        \"avg_length\": round(avg_length, 1),\n",
    "        \"embedding_diversity\": diversity\n",
    "    }\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name, filename in model_files.items():\n",
    "    filepath = os.path.join(model_output_folder, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for entry in data:\n",
    "            bullets = entry.get(\"target_bullets\") or entry.get(\"bullets\") or \"\"\n",
    "            paper = entry.get(\"paper\") or entry.get(\"title\", \"unknown\")\n",
    "            score = evaluate_bullets(bullets)\n",
    "            all_results.append({\n",
    "                \"paper\": paper,\n",
    "                \"model\": model_name,\n",
    "                **score\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "df.to_csv(\"model_bullet_evaluation.csv\", index=False)\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
